# -*- coding: utf-8 -*-
"""Crude_Oil_Commpdity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U-f0g65PPeJvX6RRNNZ-HQ6mHzgHk1CP
"""

# If you haven't installed yfinance yet:
# !pip install yfinance fredapi

import yfinance as yf
import pandas as pd
import numpy as np
import datetime

import yfinance as yf
import pandas as pd
import numpy as np
import datetime

start_date = "2018-01-01"
end_date = datetime.date.today().strftime("%Y-%m-%d")

# Tickers (Some examples)
oil_ticker = "CL=F"         # WTI Crude Oil Futures
usd_index_ticker = "DX-Y.NYB"  # US Dollar Index
treasury_10y_ticker = "^TNX"   # 10-year Treasury Yield
baltic_dry_ticker = "^BDI"     # Baltic Dry Index, if available on Yahoo

# Download data
oil_data = yf.download(oil_ticker, start=start_date, end=end_date)
usd_data = yf.download(usd_index_ticker, start=start_date, end=end_date)
tnx_data = yf.download(treasury_10y_ticker, start=start_date, end=end_date)

oil_data = oil_data[['Close']].rename(columns={'Close': 'WTI_Close'})
usd_data = usd_data[['Close']].rename(columns={'Close': 'USD_Index_Close'})
tnx_data = tnx_data[['Close']].rename(columns={'Close': 'TenYrYield_Close'})

combined_df = oil_data.join(usd_data, how='inner')
combined_df = combined_df.join(tnx_data, how='inner')
combined_df = combined_df.join(bdi_data, how='inner')

print(combined_df.head())

combined_df.fillna(method='ffill', inplace=True)
combined_df.dropna(inplace=True)  # If the data is still inconsistent, might need a more flexible approach

combined_df['WTI_Returns'] = combined_df['WTI_Close'].pct_change()
combined_df['USD_Returns'] = combined_df['USD_Index_Close'].pct_change()
combined_df['TenYrYield_Change'] = combined_df['TenYrYield_Close'].pct_change()
combined_df['BDI_Returns'] = combined_df['BalticDry_Close'].pct_change()

lags = 3  # number of lags
for i in range(1, lags+1):
    combined_df[f'WTI_Returns_lag{i}'] = combined_df['WTI_Returns'].shift(i)
    combined_df[f'USD_Returns_lag{i}'] = combined_df['USD_Returns'].shift(i)
    combined_df[f'TenYrYield_lag{i}'] = combined_df['TenYrYield_Change'].shift(i)
    combined_df[f'BDI_Returns_lag{i}'] = combined_df['BDI_Returns'].shift(i)

combined_df.dropna(inplace=True)  # after lagging
cols_of_interest = ['WTI_Returns', 'USD_Returns', 'TenYrYield_Change', 'BDI_Returns']
corr_matrix = combined_df[cols_of_interest].corr()
print("Correlation Matrix:\n", corr_matrix)

# =========================
#    COMPREHENSIVE CODE
#     (NO BALTIC INDEX)
# =========================

# STEP 0: Install yfinance if you haven't already
# !pip install yfinance

import yfinance as yf
import pandas as pd
import numpy as np
import datetime
import matplotlib.pyplot as plt

# For cleaner plots (optional)
plt.rcParams.update({'figure.figsize': (10, 5)})

# -------------------------
# 1) DEFINE DATE RANGE & TICKERS
# -------------------------
start_date = "2018-01-01"
end_date = datetime.date.today().strftime("%Y-%m-%d")

oil_ticker = "CL=F"         # WTI Crude Oil Futures
usd_index_ticker = "DX-Y.NYB"  # US Dollar Index
treasury_10y_ticker = "^TNX"   # 10-year Treasury Yield

# -------------------------
# 2) FETCH DATA FROM YFINANCE
# -------------------------
print("Fetching data from Yahoo Finance...")

oil_data = yf.download(oil_ticker, start=start_date, end=end_date)
usd_data = yf.download(usd_index_ticker, start=start_date, end=end_date)
tnx_data = yf.download(treasury_10y_ticker, start=start_date, end=end_date)

# -------------------------
# 3) RENAME & KEEP ONLY 'Close' COLUMNS
# -------------------------
oil_data = oil_data[['Close']].rename(columns={'Close': 'WTI_Close'})
usd_data = usd_data[['Close']].rename(columns={'Close': 'USD_Index_Close'})
tnx_data = tnx_data[['Close']].rename(columns={'Close': 'TenYrYield_Close'})

# -------------------------
# 4) MERGE ALL DATAFRAMES
# -------------------------
print("\nMerging DataFrames with an INNER join...")
combined_df = oil_data.join(usd_data, how='inner')
combined_df = combined_df.join(tnx_data, how='inner')

print("\nHead of combined data (before cleaning):\n", combined_df.head())

# -------------------------
# 5) HANDLE MISSING VALUES
# -------------------------
print("\nChecking missing values:")
missing_summary = combined_df.isnull().sum()
print(missing_summary)

# Forward fill or drop NAs
combined_df.fillna(method='ffill', inplace=True)
combined_df.dropna(inplace=True)

print("\nMissing values after cleaning:")
print(combined_df.isnull().sum())

# -------------------------
# 6) BASIC VISUAL CHECK
# -------------------------
combined_df[['WTI_Close', 'USD_Index_Close', 'TenYrYield_Close']].plot(subplots=True, layout=(3,1), title="Time Series Overview")
plt.tight_layout()
plt.show()

# -------------------------
# 7) FEATURE ENGINEERING (Returns, Lagging)
# -------------------------
combined_df['WTI_Returns'] = combined_df['WTI_Close'].pct_change()
combined_df['USD_Returns'] = combined_df['USD_Index_Close'].pct_change()
combined_df['TenYrYield_Change'] = combined_df['TenYrYield_Close'].pct_change()

# Drop initial NaNs from .pct_change()
combined_df.dropna(inplace=True)

# Create lag features (example: 3 lags)
lags = 3
for i in range(1, lags+1):
    combined_df[f'WTI_Returns_lag{i}'] = combined_df['WTI_Returns'].shift(i)
    combined_df[f'USD_Returns_lag{i}'] = combined_df['USD_Returns'].shift(i)
    combined_df[f'TenYrYield_Change_lag{i}'] = combined_df['TenYrYield_Change'].shift(i)

# Drop any rows with new NaNs introduced by lagging
combined_df.dropna(inplace=True)

# -------------------------
# 8) CORRELATION ANALYSIS
# -------------------------
cols_of_interest = [
    'WTI_Returns', 'USD_Returns', 'TenYrYield_Change',
    'WTI_Returns_lag1', 'USD_Returns_lag1', 'TenYrYield_Change_lag1'
]

corr_matrix = combined_df[cols_of_interest].corr()
print("\nCorrelation Matrix:\n", corr_matrix)

# (Optional) Plot correlation matrix heatmap
import seaborn as sns

plt.figure(figsize=(8,6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap of Selected Features")
plt.show()

# -------------------------
# END OF SCRIPT
# -------------------------
print("\nData preprocessing complete. Please review the printed outputs and charts!")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# ----------------------------------------------
# Assume combined_df is already created from merging:
# oil_data, usd_data, and tnx_data.
# For example, combined_df might currently have MultiIndex columns.
# ----------------------------------------------

# Step 1: Flatten the MultiIndex columns, if present.
if isinstance(combined_df.columns, pd.MultiIndex):
    new_columns = []
    for col in combined_df.columns.values:
        # If the second level is not empty, use it; otherwise use the first level.
        if len(col) > 1 and col[1] != '':
            new_columns.append(col[1])
        else:
            new_columns.append(col[0])
    combined_df.columns = new_columns

# Remove any columns that are empty strings.
combined_df = combined_df.loc[:, combined_df.columns != '']
print("Flattened columns:", combined_df.columns.tolist())

# Step 2: Rename the columns to intuitive names.
# We expect the relevant columns from Yahoo to be:
#   'CL=F' for WTI Crude Oil, 'DX-Y.NYB' for US Dollar Index, '^TNX' for 10-year Treasury Yield.
combined_df = combined_df.rename(columns={
    'CL=F': 'WTI_Close',
    'DX-Y.NYB': 'USD_Index_Close',
    '^TNX': 'TenYrYield_Close'
})
print("Renamed columns:", combined_df.columns.tolist())

# Step 3: Compute daily returns for each series.
combined_df['WTI_Returns'] = combined_df['WTI_Close'].pct_change()
combined_df['USD_Returns'] = combined_df['USD_Index_Close'].pct_change()
combined_df['TenYrYield_Change'] = combined_df['TenYrYield_Close'].pct_change()

# Drop rows with NA values resulting from pct_change.
combined_df.dropna(inplace=True)

# (Optional) Visual check of the new columns
combined_df[['WTI_Close', 'USD_Index_Close', 'TenYrYield_Close']].plot(subplots=True, layout=(3,1), title="Price Time Series")
plt.tight_layout()
plt.show()

# Step 4: Create the target column: next-day WTI return.
combined_df['WTI_Future_Return'] = combined_df['WTI_Returns'].shift(-1)

# Drop rows where the target is NA (typically the very last row).
combined_df.dropna(subset=['WTI_Future_Return'], inplace=True)
print("Missing values in WTI_Future_Return after dropna:", combined_df['WTI_Future_Return'].isnull().sum())
print("Columns available:", combined_df.columns.tolist())

# For clarity, let's inspect the head of the DataFrame.
print("Head of DataFrame:\n", combined_df.head())

# Step 5: Create lag features (using 3 lags as an example)
lags = 3
for i in range(1, lags+1):
    combined_df[f'WTI_Returns_lag{i}'] = combined_df['WTI_Returns'].shift(i)
    combined_df[f'USD_Returns_lag{i}'] = combined_df['USD_Returns'].shift(i)
    combined_df[f'TenYrYield_Change_lag{i}'] = combined_df['TenYrYield_Change'].shift(i)

# Drop rows with NA values introduced by lagging.
combined_df.dropna(inplace=True)

# Step 6: Define features and target variable for the ML model.
feature_cols = [
    'WTI_Returns', 'USD_Returns', 'TenYrYield_Change',
    'WTI_Returns_lag1', 'WTI_Returns_lag2', 'WTI_Returns_lag3',
    'USD_Returns_lag1', 'USD_Returns_lag2', 'USD_Returns_lag3',
    'TenYrYield_Change_lag1', 'TenYrYield_Change_lag2', 'TenYrYield_Change_lag3'
]

X = combined_df[feature_cols]
y = combined_df['WTI_Future_Return']

# Step 7: Time-based Train/Test Split.
# We'll split by date to avoid look-ahead bias. For example, training on data before 2022-01-01.
split_date = '2022-01-01'
X_train = X.loc[:split_date]
X_test  = X.loc[split_date:]
y_train = y.loc[:split_date]
y_test  = y.loc[split_date:]

# Step 8: Train a Random Forest Regressor.
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# Step 9: Evaluate Model Performance.
y_pred = rf.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Test MSE: {mse:.6f}")
print(f"Test R^2: {r2:.4f}")

# Plot actual vs. predicted next-day returns.
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}, index=y_test.index)
results_df.plot(title="Random Forest: Next-Day WTI Returns Prediction")
plt.xlabel("Date")
plt.ylabel("WTI Return")
plt.show()

# Step 10: Display Feature Importances.
importances = rf.feature_importances_
importance_df = pd.DataFrame({
    'Feature': feature_cols,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)
print("\nFeature Importances:")
print(importance_df)

# Step 11: Build a Simple Trading Strategy & Backtest.
# Define a trading signal: if predicted return > 0, signal is +1 (long), otherwise -1 (short).
results_df['Predicted_Signal'] = np.where(results_df['Predicted'] > 0, 1, -1)
# Shift the signal by one day to use today's prediction for tomorrow's trade.
results_df['Strategy_Signal'] = results_df['Predicted_Signal'].shift(1)
results_df['Strategy_Signal'].fillna(0, inplace=True)

# Strategy daily return: actual next-day return multiplied by the strategy signal.
results_df['Strategy_Daily_Return'] = results_df['Actual'] * results_df['Strategy_Signal']
# Compute cumulative returns.
results_df['Strategy_Cum_Return'] = (1 + results_df['Strategy_Daily_Return']).cumprod()

# Plot the strategy's cumulative return.
results_df['Strategy_Cum_Return'].plot(title="Strategy Cumulative Return (Random Forest)")
plt.xlabel("Date")
plt.ylabel("Cumulative Return")
plt.show()

# Step 12: Compute Performance Metrics.
final_return = results_df['Strategy_Cum_Return'].iloc[-1] - 1
print(f"Final Strategy Return: {final_return*100:.2f}% over the test period")

# Calculate Sharpe Ratio (assuming 252 trading days per year).
daily_ret = results_df['Strategy_Daily_Return']
sharpe_ratio = (daily_ret.mean() / daily_ret.std()) * np.sqrt(252)
print(f"Strategy Sharpe Ratio: {sharpe_ratio:.2f}")

